# -*- coding: utf-8 -*-
"""Spark_hometask_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10zOQGs8qn6v2QpUKSUxrO4mkXxZrdejR

# Изучение Spark Structure Streaming
Условие: используйте источник rate, напишите код, который создаст дополнительный столбец, который будет выводить сумму только нечётных чисел.
"""

!pip install pyspark

# Импорт модулей
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when
import time

# Проверка на существование запущенной spark-сессии
# необязательно при использовании синтаксиса - 'getOrCreate()' при создании spark-сессии

if 'spark' in locals():
  spark.stop()

# Создание сессии Spark
spark = SparkSession.builder \
    .appName("SumOddNumbers") \
    .getOrCreate()

# Чтение данных из источника rate
df = spark.readStream.format("rate").option("rowsPerSecond", 1).load()

# Определение функции для вычисления суммы нечётных чисел
def sum_odd_numbers(df):
    return df.withColumn('sum_of_odds', when(col('value') % 2 != 0, col('value')).otherwise(0))

# Применение функции к DataFrame
df_with_sum = sum_odd_numbers(df)

# Вывод результата в консоль
query = df_with_sum.writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

# # Время ожидания в миллисекундах (например, 10 секунд)
# timeout = 10000

# try:
#     # Ожидание завершения потока в течение timeout миллисекунд
#     query.awaitTermination(timeout)
# except KeyboardInterrupt:
#     # Принудительная остановка в случае прерывания (например, через Ctrl+C)
#     print("Terminating the query due to interrupt.")
# finally:
#     # Остановка запроса и завершение сессии Spark
#     query.stop()
#     spark.stop()

# # Этот вариант НЕ РАБОТАЕТ в Google Colab

# Вариант 2
# Использование цикла для периодической проверки состояния стрима и завершения при необходимости

# Время ожидания в секундах (например, 10 секунд)
timeout = 10
start_time = time.time()

try:
    while query.isActive:
        current_time = time.time()
        elapsed_time = current_time - start_time
        if elapsed_time > timeout:
            print("Timeout reached. Terminating the query.")
            query.stop()
            break
        time.sleep(1)
except KeyboardInterrupt:
    print("Terminating the query due to interrupt.")
finally:
    query.stop()
    spark.stop()