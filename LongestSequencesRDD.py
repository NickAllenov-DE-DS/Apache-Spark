# -*- coding: utf-8 -*-
"""Apache_Spark_hometask_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D0pnTrhJR2S824F65FiDvu-xMZSsLbGI

Урок 1. SQL & BigData    
Найти самую длинную последовательность упорядоченных чисел в RDD и вывести её.
"""

# Импорт необходимых модулей
from pyspark.sql import SparkSession
import random

# Определение функции для генерации последовательностей
def generate_ordered_sequences(num_sequences, min_length, max_length):
    sequences = []
    for _ in range(num_sequences):
        length = random.randint(min_length, max_length)
        start = random.randint(0, 50)
        sequence = list(range(start, start + length))
        sequences.append(sequence)
    return sequences

# Инициализация Spark-сессии
spark = SparkSession.builder\
  .master("local[*]")\
  .appName("LongestOrderedSequence")\
  .getOrCreate()
sc = spark.sparkContext

# Определение аргументов
NUM_SEQUENCES = 10
MIN_LENGTH = 5
MAX_LENGTH = 15

# Генерация последовательностей и создание RDD
sequences = generate_ordered_sequences(NUM_SEQUENCES, MIN_LENGTH, MAX_LENGTH)
rdd = sc.parallelize(sequences)

# Вывод сгенерированных последовательностей
# for seq in sequences:
#   print(f'Последовательность: {seq},\t количество элементов - {len(seq)}')

# Поиск длины самой длинной последовательности с использованием reduce
max_length = rdd.map(len).max()
# или так:
# max_length = rdd.map(len).reduce(lambda a, b: a if a > b else b)

# Поиск всех последовательностей, которые имеют максимальную длину и их сборка
# Используем flatMap для уменьшения объема данных
longest_sequences_rdd = rdd.filter(lambda seq: len(seq) == max_length)

# Ограничиваем количество элементов для обработки и печати
longest_sequences = longest_sequences_rdd.collect()
# Можно использовать .take(n) для ограничения
# longest_sequences = longest_sequences_rdd.take(n)

# Вывод всех самых длинных последовательностей
print("Самые длинные последовательности:")
for l_seq in longest_sequences:
    print(f'{l_seq}, количество элементов - {len(l_seq)}')

# Завершение Spark-сессии
spark.stop()